{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 12080083,
          "sourceType": "datasetVersion",
          "datasetId": 7604504
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "periodontitis final",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "execution_failed": "2025-06-06T12:35:45.776Z"
        },
        "id": "OqcF-iNnbDOm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Data Augmentation ---\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(25),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- Custom Dataset Class ---\n",
        "class PeriodontitisDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # 0 for 'no', 1 for 'yes'\n",
        "        for label, folder in enumerate(['no', 'yes']):\n",
        "            folder_path = os.path.join(root_dir, folder)\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(folder_path, img_name))\n",
        "                    self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- Configuration and Device Setup ---\n",
        "DATA_ROOT = '/kaggle/input/periodontitis-dataset/input'\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 1e-4\n",
        "PATIENCE = 10 # For early stopping\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Create Dataset and Dataloaders ---\n",
        "full_dataset = PeriodontitisDataset(root_dir=DATA_ROOT, transform=transform_train)\n",
        "\n",
        "# Split into training and validation sets (e.g., 80% train, 20% validation)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply appropriate transforms for validation set (no augmentation)\n",
        "val_dataset.dataset.transform = transform_val\n",
        "\n",
        "# Check class balance in the *training* dataset for weighted sampling\n",
        "train_labels_indices = train_dataset.indices\n",
        "train_labels = [full_dataset.labels[i] for i in train_labels_indices]\n",
        "\n",
        "no_count_train = sum(1 for l in train_labels if l == 0)\n",
        "yes_count_train = sum(1 for l in train_labels if l == 1)\n",
        "print(f\"Training set - Healthy (no) cases: {no_count_train}\")\n",
        "print(f\"Training set - Periodontitis (yes) cases: {yes_count_train}\")\n",
        "\n",
        "# Handle class imbalance with weighted sampling for the training set\n",
        "class_counts = np.bincount(train_labels)\n",
        "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
        "sample_weights = class_weights[train_labels]\n",
        "sampler = torch.utils.data.WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False, # No need to shuffle validation data\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# --- Model Initialization (ResNet18 with transfer learning) ---\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) # Use weights=... instead of pretrained=True\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False # Freeze early layers\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# --- Loss Function, Optimizer, and Scheduler ---\n",
        "# Calculate class weights for BCEWithLogitsLoss based on training data\n",
        "pos_weight = torch.tensor([(len(train_labels) - sum(train_labels)) / sum(train_labels)])\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.1, patience=5, verbose=True\n",
        ")\n",
        "\n",
        "# --- Training Loop ---\n",
        "best_f1 = 0\n",
        "no_improve = 0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_f1': [], 'val_acc': [], 'val_precision': [], 'val_recall': []}\n",
        "\n",
        "print(f\"\\n{'='*40}\")\n",
        "print(f\"Starting training on the full dataset\")\n",
        "print(f\"{'='*40}\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} (Train)')\n",
        "\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Gradient clipping\n",
        "\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    history['train_loss'].append(epoch_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar_val = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} (Validation)')\n",
        "        for inputs, labels in progress_bar_val:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    # Calculate metrics\n",
        "    val_acc = accuracy_score(all_labels, all_preds)\n",
        "    val_f1 = f1_score(all_labels, all_preds)\n",
        "    val_precision = precision_score(all_labels, all_preds)\n",
        "    val_recall = recall_score(all_labels, all_preds)\n",
        "\n",
        "    history['val_f1'].append(val_f1)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_precision'].append(val_precision)\n",
        "    history['val_recall'].append(val_recall)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - \"\n",
        "          f\"Train Loss: {epoch_loss:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | \"\n",
        "          f\"Acc: {val_acc:.4f} | \"\n",
        "          f\"F1: {val_f1:.4f} | \"\n",
        "          f\"Precision: {val_precision:.4f} | \"\n",
        "          f\"Recall: {val_recall:.4f}\")\n",
        "\n",
        "    scheduler.step(val_f1) # Update scheduler\n",
        "\n",
        "    # Early stopping check\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'best_model_full_dataset.pth')\n",
        "        no_improve = 0\n",
        "        print(f\"Saved new best model (F1: {best_f1:.4f})\")\n",
        "    else:\n",
        "        no_improve += 1\n",
        "        if no_improve >= PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "# --- Plotting Training History ---\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history['val_f1'], label='Validation F1')\n",
        "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "plt.title('Performance Metrics History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history['val_precision'], label='Validation Precision')\n",
        "plt.plot(history['val_recall'], label='Validation Recall')\n",
        "plt.title('Precision and Recall History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history_full_dataset.png')\n",
        "plt.close()\n",
        "\n",
        "# --- Final Evaluation on the best model ---\n",
        "print(\"\\n--- Final Evaluation on Best Model ---\")\n",
        "model.load_state_dict(torch.load('best_model_full_dataset.pth'))\n",
        "model.eval()\n",
        "\n",
        "final_all_preds = []\n",
        "final_all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > 0.5).float()\n",
        "        final_all_preds.extend(preds.cpu().numpy())\n",
        "        final_all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "final_acc = accuracy_score(final_all_labels, final_all_preds)\n",
        "final_f1 = f1_score(final_all_labels, final_all_preds)\n",
        "final_precision = precision_score(final_all_labels, final_all_preds)\n",
        "final_recall = recall_score(final_all_labels, final_all_preds)\n",
        "\n",
        "print(f\"Final Validation Accuracy: {final_acc:.4f}\")\n",
        "print(f\"Final Validation F1 Score: {final_f1:.4f}\")\n",
        "print(f\"Final Validation Precision: {final_precision:.4f}\")\n",
        "print(f\"Final Validation Recall: {final_recall:.4f}\")\n",
        "\n",
        "# Save final results\n",
        "with open('final_model_results.txt', 'w') as f:\n",
        "    f.write(f\"Final Validation Accuracy: {final_acc:.4f}\\n\")\n",
        "    f.write(f\"Final Validation F1 Score: {final_f1:.4f}\\n\")\n",
        "    f.write(f\"Final Validation Precision: {final_precision:.4f}\\n\")\n",
        "    f.write(f\"Final Validation Recall: {final_recall:.4f}\\n\")\n",
        "\n",
        "print(\"Training and final evaluation complete!\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "_0WVWwMcbDOo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}